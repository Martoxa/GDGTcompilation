# Compilation of GDGTs
I am dropping here the dataset as I have so far, as well as some tools I have developed that could be useful to manipulate and showcase the dataset.
As you can see in both the Compiled_data.xlsx or the Test_GDGT_compilation.csv I am trying to put all samples toghether following some principles.
1) Traceability: A big problem I am encountering is the samples being repeated by different datasets, but also the references slowly degrading (errors on citation or not citing the original source). I think we should use manuscripts DOIs as much as possible to maintain a stable reference. Additionally we need to be able to identofy repeting samples in a relatively easy way. For this I am trying to convert coordinates to geohashes with 9 levels (tens of meters resolution). Basically this will convert the Lat/Lon data into a single 9 character string which preserved the data. I have been using geohashTools in R to convert them. Combining the geohash and the DOI reference index I think we can flag repeating samples, as then it is mostly a matter of cross referencing the geohash strings to their reference, if multiple samples have the same location but are referenced by different publications, it probably means those are repeating samples.
2) Accesibility: To make things easier I just started numbering the samples, and that will be usefull for indexing during the cleanup stage. Since we are dealing with very large datasets now I figured we can save some string space by using hexadecimal numbers for IDing the samples. Ultimately I think that once the dataset is complete we should develop individul tags for the samples. Currently my test tags is hexid.geohash.referenceindex, for example sample #3272, obtained from 40.2591667N	113.738611E reported by Wang et al. (2016) becomes sample 0CC8.wx0vh0vyt.43 . But we can definitely work on that.
3) Usability: Ultimately the idea is that the compilation can be easily ised by everyone with minimal effort. I have added some functions I have developed to more quickly do analyses. For example with the function linearCalib() one should be able to generate an environment reconstruction using one of the published calibrations directly from peak reas or fractional abundances in a single line for example: linearCalib(dataArea,env="Temperature",calibration = "Russell")

I think for using this repository we can each work on individual branches as we work either cleaning the data or the code, and when things look good we can merge branches.
